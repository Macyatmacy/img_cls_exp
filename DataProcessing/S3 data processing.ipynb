{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"pn_deploy\"\n",
    "\n",
    "train_prefix = \"train\"\n",
    "val_prefix = \"validation\"\n",
    "\n",
    "train_data = \"s3://{}/{}/{}/\".format(bucket, project_name, train_prefix)\n",
    "validation_data = \"s3://{}/{}/{}/\".format(bucket, project_name, val_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download or Update Data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(bucket_name, prefix):\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket=bucket_name\n",
    "    my_bucket = s3.Bucket(bucket)\n",
    "    location_list = []\n",
    "    for (bucket_name, key) in map(lambda x: (x.bucket_name, x.key), my_bucket.objects.filter(Prefix=prefix)):\n",
    "        data_location = \"s3://{}/{}\".format(bucket_name, key)\n",
    "        location_list.append(data_location)\n",
    "    # Remove the root folder path\n",
    "    if \"s3://{}/{}/\".format(bucket_name, prefix) in location_list:\n",
    "        location_list.remove(\"s3://{}/{}/\".format(bucket_name, prefix))\n",
    "    return location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_normal = get_file_list(bucket,\"pn_deploy/normal_1000\")\n",
    "list_pneumonia = get_file_list(bucket,\"pn_deploy/pneumonia_1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download data\n",
    "for l in list_normal:\n",
    "    data_source1 = S3Downloader.download(\n",
    "    local_path=\"pn/data/normal/\",\n",
    "    s3_uri=l,\n",
    "    sagemaker_session=session,\n",
    "    )\n",
    "\n",
    "for l in list_pneumonia:\n",
    "    data_source1 = S3Downloader.download(\n",
    "    local_path=\"pn/data/pneumonia/\",\n",
    "    s3_uri=l,\n",
    "    sagemaker_session=session,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate annotations\n",
    "filePath = 'pn/data/normal'\n",
    "l = os.listdir(filePath)\n",
    "ant={}\n",
    "for n in l:\n",
    "    name,_ = n.split('.')\n",
    "    ant[name] = 'normal'\n",
    "with open('pn/annotations/normal.txt', 'w') as f:\n",
    "    for n, c in ant.items():\n",
    "        f.write(str(n)+\" \"+str(c)+\"\\n\")\n",
    "\n",
    "filePath = 'pn/data/pneumonia'\n",
    "l = os.listdir(filePath)\n",
    "ant={}\n",
    "for n in l:\n",
    "    name,_ = n.split('.')\n",
    "    ant[name] = 'pneumonia'\n",
    "with open('pn/annotations/pneumonia.txt', 'w') as f:\n",
    "    for n, c in ant.items():\n",
    "        f.write(str(n)+\" \"+str(c)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read annotations\n",
    "def get_annotations(file_path, annotations={}):\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        rows = f.read().splitlines()\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        image_name, class_name = row.split(' ')\n",
    "        image_name = image_name + '.jpeg'\n",
    "        \n",
    "        annotations[image_name] = class_name\n",
    "    \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total normal examples 1000\n",
      "Total pneumonia examples 1000\n"
     ]
    }
   ],
   "source": [
    "# read annotations\n",
    "annotations_normal={}\n",
    "annotations_pneumonia={}\n",
    "annotations_normal = get_annotations('pn/annotations/normal.txt',annotations_normal)\n",
    "annotations_pneumonia = get_annotations('pn/annotations/pneumonia.txt',annotations_pneumonia)\n",
    "\n",
    "total_count = len(annotations_normal.keys())\n",
    "print('Total normal examples', total_count)\n",
    "total_count = len(annotations_pneumonia.keys())\n",
    "print('Total pneumonia examples', total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NORMAL2-IM-0588-0001.jpeg', 'normal')\n",
      "('person55_bacteria_263.jpeg', 'pneumonia')\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(annotations_normal.items())))\n",
    "print(next(iter(annotations_pneumonia.items())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data and Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split and copy file\n",
    "import os\n",
    "classes = ['normal', 'pneumonia']\n",
    "sets = ['train', 'validation']\n",
    "root_dir = 'pn/custom_data'\n",
    "\n",
    "if not os.path.isdir(root_dir):\n",
    "    os.mkdir(root_dir)\n",
    "    \n",
    "for set_name in sets:\n",
    "    if not os.path.isdir(os.path.join(root_dir, set_name)):\n",
    "        os.mkdir(os.path.join(root_dir, set_name))\n",
    "    for class_name in classes:\n",
    "        folder = os.path.join(root_dir, set_name, class_name)\n",
    "        if not os.path.isdir(folder):\n",
    "            os.mkdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, class_name in annotations_normal.items():\n",
    "    target_set = 'validation' if random.randint(0, 99) < 20 else 'train'\n",
    "    target_path = os.path.join(root_dir, target_set, class_name, image)\n",
    "    shutil.copy(os.path.join('pn/data/normal', image), target_path)\n",
    "\n",
    "for image, class_name in annotations_pneumonia.items():\n",
    "    target_set = 'validation' if random.randint(0, 99) < 20 else 'train'\n",
    "    target_path = os.path.join(root_dir, target_set, class_name, image)\n",
    "    shutil.copy(os.path.join('pn/data/pneumonia', image), target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_counts = {\n",
    "    'train': 0,\n",
    "    'validation': 0\n",
    "}\n",
    "\n",
    "for set_name in sets:\n",
    "    for class_name in classes:\n",
    "        path = os.path.join(root_dir, set_name, class_name)\n",
    "        count = len(os.listdir(path))\n",
    "        print(path, 'has', count, 'images')\n",
    "        sets_counts[set_name] += count\n",
    "\n",
    "print(sets_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket_name = bucket\n",
    "\n",
    "print('Uploading to S3..')\n",
    "s3_data_path = sagemaker_session.upload_data(path=root_dir, bucket=bucket_name, key_prefix='pn_deploy')\n",
    "\n",
    "print('Uploaded to', s3_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
